---
title: 'Overt visual attention and value computation in
complex risky choice'

# Authors
# If you created a profile for a user (e.g. the default `admin` user), write the username (folder name) here
# and it will be replaced with their full name and linked to their profile.
authors:
  - admin
  - Jacob Elsey
  - Aurelien Wyngaard
  - Youping Yang
  - Aaron Sampson
  - Erik Emeric
  - Moshe Glickman
  - Marius Usher
  - Dino Levy
  - Veit Stuphorn
  - Ernst Niebur

# Author notes (optional)
#author_notes:

date: '2013-07-01T00:00:00Z'
doi: ''

# Schedule page publish date (NOT publication's date).
publishDate: '2017-01-01T00:00:00Z'

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ['3']

# Publication name and optional abbreviated publication name.
publication: In *bioRxiv*
publication_short: In *bioRxiv*

abstract: 
  Models of multi-attribute decision making vary on whether all (or only part of the)
  information available is being processed. The models also vary on whether the
  preference formation is based on within-alternative or within-attribute processing. Here
  we carry out an experimental study in which we rely on lottery-options, and we vary the
  task complexity, from simple (2 options with 2 attributes each) to complex (4 options
  with 4 attributes each). In addition we monitor eye-gaze during the decision formation,
  in order to directly observe the way in which participants attend to decision-relevant
  information. We then compare a large set of models, of different levels of complexity, by
  considering the dynamic interactions between uncertainty, attention and pairwise
  comparisons between attribute values, in their ability to account for the choice data. We
  find that two models outperform all others. The first is the two-layer leaky-competing
  accumulator based on prospect theory (LCA-PT), which predicts human choices on the
  simpler task better than any other model. We call the second model, which is
  introduced in this study, the Attention and Memory-guided PROMETHEE (AMP)
  model. It is modified from a previous model (PROMETHEE) developed in management
  science, designed to deal with highly complex decision problems. Our results show that
  this model performs best in the complex lottery task. Both of these models use the
  sequence of observed eye movements for each participant to capture the allocation of
  attention to specific options and attributes during the decision process, but make
  different assumptions about the effect of attention on decision making. Our results
  suggest that, when faced with complex choice problems, people form their preference
  based on attention-guided pairwise, within-attribute, value-comparisons.
# Summary. An optional shortened abstract.
summary: 
  Most decisions we make in daily life require to take into account a large number of
  different factors. It is generally believed that we select some of them, use only those for
  the decision process, and disregard the others. In many experimental studies of decision
  making, this process is dramatically simplified and only very few factors are included.
  One typical paradigm is choosing between two alternatives (gambles) where each of
  which allows to win a certain amount with a certain probability. In this study, we
  juxtapose such a simple situation with a more complex one, with more alternatives and
  more factors. We also measure which of these factors the decision makers actually are
  interested in (i.e. which they are looking at). We then impplement a dozen
  computational models, each designed to predict the decision a human makes based on
  which factors each individual looked at. We find two models that predict the choices
  significantly better than all others. The two models have in common that they, first, use
  explicitly the order in which they collect the information about the different choices and
  second, keep this information in memory.
tags: []

# Display this page in the Featured widget?
featured: false

# Custom links (uncomment lines below)
# links:
# - name: Custom Link
#   url: http://example.org

url_pdf: ''
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
image:
  caption: 'Overview of AMP model'
  focal_point: ''
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects:
  - []

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: example
---
